{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {'image': open('/Users/peterfagan/Desktop/test.jpeg', 'rb')}\n",
    "response = requests.post('http://0.0.0.0:5000/predict', files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1515.2666', '927.73535', '1920.0', '1275.6698'],\n",
       " ['667.66003', '759.37933', '1121.6791', '1053.1754'],\n",
       " ['1300.2684', '1278.602', '1790.8867', '1280.0'],\n",
       " ['1309.769', '1278.6112', '1782.2643', '1280.0'],\n",
       " ['1312.0555', '1278.6078', '1782.4525', '1280.0']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes = [np.array(x).astype(float) for x in annotations['boxes']]\n",
    "labels = np.array(annotations['labels']).astype('int')\n",
    "scores = np.array(annotations['scores']).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1515.2666 ,  927.73535, 1920.     , 1275.6698 ]),\n",
       " array([ 667.66003,  759.37933, 1121.6791 , 1053.1754 ]),\n",
       " array([1300.2684, 1278.602 , 1790.8867, 1280.    ]),\n",
       " array([1309.769 , 1278.6112, 1782.2643, 1280.    ]),\n",
       " array([1312.0555, 1278.6078, 1782.4525, 1280.    ])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99185467, 0.23940782, 0.19031687, 0.14833756, 0.14630488])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"boxes\":[[\"1515.2666\",\"927.73535\",\"1920.0\",\"1275.6698\"],[\"667.66003\",\"759.37933\",\"1121.6791\",\"1053.1754\"],[\"1300.2684\",\"1278.602\",\"1790.8867\",\"1280.0\"],[\"1309.769\",\"1278.6112\",\"1782.2643\",\"1280.0\"],[\"1312.0555\",\"1278.6078\",\"1782.4525\",\"1280.0\"]],\"labels\":[\"1\",\"1\",\"1\",\"2\",\"3\"],\"scores\":[\"0.9918546676635742\",\"0.23940782248973846\",\"0.19031687080860138\",\"0.14833755791187286\",\"0.1463048756122589\"]}\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import cv2\n",
    "# from herbie_vision.utils.train_utils import get_customer_backbone_fast_rcnn\n",
    "# from herbie_vision.utils.gcp_utils import download_blob, upload_blob\n",
    "\n",
    "from google.cloud import storage\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/peterfagan/Desktop/gcp/waymo-2d-object-detection-514eeefdb0a3.json\"\n",
    "\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "\n",
    "    print(\n",
    "        \"Blob {} downloaded to {}.\".format(\n",
    "            source_blob_name, destination_file_name\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def get_custom_backbone_fast_rcnn(num_classes):\n",
    "    backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n",
    "    backbone.out_channels = 1280\n",
    "    anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
    "                                       aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "    roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],\n",
    "                                                    output_size=7,\n",
    "                                                    sampling_ratio=4)\n",
    "    model = FasterRCNN(backbone,\n",
    "                       num_classes=num_classes,\n",
    "                       rpn_anchor_generator=anchor_generator,\n",
    "                       box_roi_pool=roi_pooler)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def detect_object(request):\n",
    "  # Instantiate model\n",
    "  model = get_custom_backbone_fast_rcnn(4)\n",
    "\n",
    "  # Download model weights\n",
    "  client = storage.Client()\n",
    "  bucket = client.get_bucket('herbie_trained_models') \n",
    "  download_blob('herbie_trained_models', 'fastrcnn.pth', '/tmp/fastrcnn.pth')\n",
    "\n",
    "  # Read in model weights \n",
    "  model.load_state_dict(torch.load(\"/tmp/fastrcnn.pth\", map_location=torch.device('cpu')))\n",
    "  model.eval()\n",
    "\n",
    "  # Get method\n",
    "  if request.method == 'GET':\n",
    "        return \"Welcome to Herbie Vision\"\n",
    "\n",
    "  # Accept/Read user request and convert data to tensor\n",
    "  if request.method == 'POST':\n",
    "\n",
    "      data = request.get_json()\n",
    "      img_file = data['image_uri']\n",
    "\n",
    "      # Read in image file\n",
    "      filename = img_file.split('/')[-1]\n",
    "      download_blob('herbie_user_input', filename, '/tmp/{}'.format(filename))\n",
    "      img = cv2.imread('/tmp/{}'.format(filename))\n",
    "      img = torch.tensor(img).permute(2,0,1).float()    \n",
    "\n",
    "      # Perform prediction\n",
    "      outputs = model(img)\n",
    "      print(outputs)\n",
    "\n",
    "      # Create figure\n",
    "      img = cv2.imread(filename)\n",
    "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "      bbox = outputs[0]['boxes']\n",
    "      scores = outputs[0]['scores']\n",
    "      labels = outputs[0]['labels']\n",
    "\n",
    "      keep = torchvision.ops.nms(bbox,scores,0.2)\n",
    "      labels = [int(x.detach().to('cpu')) for idx, x in enumerate(labels) if idx in keep]\n",
    "      bbox = [x.detach().to('cpu') for idx, x in enumerate(bbox) if idx in keep]\n",
    "\n",
    "      my_dpi=100\n",
    "      fig, ax = plt.subplots(figsize=(20,10), dpi=my_dpi)\n",
    "      ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "      ax.set_axis_off()\n",
    "      fig.add_axes(ax)\n",
    "\n",
    "      i=0\n",
    "      scores_ind = [idx for idx,x in enumerate(scores) if x>0.4] # Filter for scores greater than certain threshold\n",
    "      for idx, entry in enumerate(bbox):\n",
    "          if idx in scores_ind:\n",
    "              h = entry[2]-entry[0]\n",
    "              w = entry[3]-entry[1]\n",
    "\n",
    "              # Create a Rectangle patch\n",
    "              rect = patches.Rectangle((entry[0],entry[1]), h, w, linewidth=4, edgecolor=colors_map[str(labels[idx])], facecolor='none')\n",
    "\n",
    "              # Add classification category\n",
    "              plt.text(entry[0], entry[1], s=labels_map[str(labels[idx])], \n",
    "                      color='white', verticalalignment='top',\n",
    "                      bbox={'color': colors_map[str(labels[idx])], 'pad': 0},\n",
    "                      font={'size':25})\n",
    "\n",
    "          # Add the patch to the Axes\n",
    "          ax.add_patch(rect)\n",
    "          i+=1\n",
    "      ax.imshow(img, aspect='auto')\n",
    "      plt.savefig('/tmp/{}'.format(filename), \n",
    "                bbox_inches = 'tight',\n",
    "                pad_inches = 0,\n",
    "                dpi=my_dpi)\n",
    "\n",
    "      upload_blob('herbie_user_input','/tmp/{}'.format(filename),filename)\n",
    "\n",
    "\n",
    "  return \"gs://herbie_user_input/{}\".format(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob test.jpeg downloaded to ./test.jpeg.\n"
     ]
    }
   ],
   "source": [
    "client = storage.Client()\n",
    "bucket = client.get_bucket('herbie_trained_models') \n",
    "filename=\"test.jpeg\"\n",
    "download_blob('herbie_user_input', filename, './{}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./{}'.format(filename))\n",
    "img = torch.tensor(img).permute(2,0,1).float()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1280, 1920])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
